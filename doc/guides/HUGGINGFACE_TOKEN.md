# Configuration du Token Hugging Face

## Pourquoi un token ?

Depuis 2024, l'API Inference de Hugging Face n√©cessite une authentification pour utiliser les mod√®les d'IA gratuitement. C'est totalement **gratuit** et prend 2 minutes.

## Comment obtenir un token (gratuit)

### 1. Cr√©er un compte Hugging Face (gratuit)

Allez sur : **https://huggingface.co/join**

- Cr√©ez un compte avec votre email
- Confirmez votre adresse email

### 2. G√©n√©rer un token d'acc√®s

Allez sur : **https://huggingface.co/settings/tokens**

1. Cliquez sur **"New token"**
2. Donnez-lui un nom (exemple : "EditeurPanovisu")
3. S√©lectionnez **"Read"** comme permission (suffisant)
4. Cliquez sur **"Generate token"**
5. **Copiez le token** (il commence par `hf_...`)

‚ö†Ô∏è **Important** : Gardez ce token secret, ne le partagez jamais publiquement !

### 3. Configurer le token dans l'application

#### Option A : Via Maven (d√©veloppement)

```bash
mvn javafx:run -Dhuggingface.token=hf_VotreTOKENici
```

#### Option B : Via ligne de commande Java

```bash
java -Dhuggingface.token=hf_VotreTOKENici -jar editeurPanovisu.jar
```

#### Option C : Variable d'environnement Windows

**PowerShell :**
```powershell
$env:JAVA_TOOL_OPTIONS="-Dhuggingface.token=hf_VotreTOKENici"
mvn javafx:run
```

**CMD :**
```cmd
set JAVA_TOOL_OPTIONS=-Dhuggingface.token=hf_VotreTOKENici
mvn javafx:run
```

#### Option D : Fichier de configuration Maven

Cr√©ez ou modifiez `~/.mavenrc` (Linux/Mac) ou `%USERPROFILE%\.mavenrc` (Windows) :

```
MAVEN_OPTS="-Dhuggingface.token=hf_VotreTOKENici"
```

#### Option E : Directement dans le code (NON RECOMMAND√â pour git)

‚ö†Ô∏è **Ne faites ceci que pour un usage personnel sans commit git !**

Dans `OllamaService.java`, ligne ~32 :
```java
private static final String HUGGINGFACE_TOKEN = "hf_VotreTOKENici";
```

**Attention** : Ne commitez JAMAIS ce fichier avec le token !

## Alternative : Utiliser Ollama (local, sans token)

Si vous pr√©f√©rez ne pas utiliser Hugging Face, vous pouvez installer **Ollama** :

### 1. T√©l√©charger Ollama

Allez sur : **https://ollama.ai/download**

### 2. Installer et configurer

```bash
# Installer le mod√®le Mistral (gratuit, ~4 GB)
ollama pull mistral

# Lancer Ollama
ollama serve
```

### 3. Avantages d'Ollama

- ‚úÖ **100% local** : fonctionne sans Internet
- ‚úÖ **Aucun token requis**
- ‚úÖ **Donn√©es priv√©es** : rien n'est envoy√© en ligne
- ‚úÖ **Rapide** : pas de latence r√©seau
- ‚ùå Requiert ~4-8 GB de RAM
- ‚ùå Requiert ~4 GB d'espace disque

## Comparaison des services

| Service | Token requis | Internet | Vitesse | Gratuit | Priv√© |
|---------|--------------|----------|---------|---------|-------|
| **Ollama** | ‚ùå Non | ‚ùå Non | ‚ö° Rapide | ‚úÖ Oui | ‚úÖ 100% |
| **Hugging Face** | ‚úÖ Oui | ‚úÖ Oui | üêå Moyen | ‚úÖ Oui | ‚ö†Ô∏è Envoy√© en ligne |

## D√©pannage

### "Service IA non disponible"

**Cause** : Ni Ollama ni Hugging Face ne sont disponibles.

**Solutions** :
1. V√©rifiez que vous avez configur√© le token Hugging Face (voir ci-dessus)
2. OU installez Ollama (voir ci-dessus)

### "HTTP 401: Invalid username or password"

**Cause** : Token Hugging Face manquant ou invalide.

**Solutions** :
1. V√©rifiez que vous avez copi√© le token complet (commence par `hf_`)
2. V√©rifiez qu'il n'y a pas d'espaces avant/apr√®s le token
3. G√©n√©rez un nouveau token sur https://huggingface.co/settings/tokens

### "HTTP 503: Model is loading"

**Cause** : Le mod√®le Hugging Face est en cours de chargement (normal la premi√®re fois).

**Solution** : Attendez 10-20 secondes et r√©essayez. L'application r√©essaie automatiquement.

### Ollama ne d√©marre pas

**Cause** : Port 11434 d√©j√† utilis√© ou service non lanc√©.

**Solutions** :
1. V√©rifiez qu'Ollama est install√© : `ollama --version`
2. Lancez le service : `ollama serve`
3. V√©rifiez qu'il √©coute : http://localhost:11434

## Support

Pour plus d'informations :
- Hugging Face : https://huggingface.co/docs/api-inference
- Ollama : https://github.com/ollama/ollama
- Documentation compl√®te : voir `DESCRIPTION_IA.md`
